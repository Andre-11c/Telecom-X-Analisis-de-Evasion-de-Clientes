# AnÃ¡lisis de EvasiÃ³n de Clientes (Churn) â€“ Telecom X

Proyecto end-to-end de exploraciÃ³n, limpieza, transformaciÃ³n y anÃ¡lisis de la evasiÃ³n (*churn*) de clientes para el reto Telecom X (LATAM). Incluye extracciÃ³n desde fuente pÃºblica (GitHub Raw), control de calidad de datos, ingenierÃ­a ligera de variables, anÃ¡lisis exploratorio, generaciÃ³n de artefactos y modelo baseline opcional.

## ğŸ¯ Objetivos
- Comprender el comportamiento de los clientes y factores asociados a la evasiÃ³n.
- Construir un pipeline reproducible (ExtracciÃ³n â†’ TransformaciÃ³n â†’ AnÃ¡lisis â†’ Informe â†’ Baseline ML).
- Generar artefactos reutilizables (parquets, mÃ©tricas, reportes CSV, checklist de requisitos).

## ğŸ“ Estructura Principal del Repo
```
â”œâ”€ TelecomX_LATAM.ipynb          # Notebook principal (flujo completo)
â”œâ”€ README.md                     # Este documento
â””â”€ data/                         # Artefactos y datasets derivados
   â”œâ”€ TelecomX_Data_local.parquet
   â”œâ”€ TelecomX_transformado.parquet
   â”œâ”€ TelecomX_limpio.parquet
   â”œâ”€ TelecomX_model_ready.parquet
   â”œâ”€ dictionary_variables.csv
   â”œâ”€ summary_columns.csv
   â”œâ”€ relevance_simple.csv
   â”œâ”€ relevance_mutual_info.csv (si sklearn disponible)
   â”œâ”€ quality_nulls.csv
   â”œâ”€ quality_overview.csv
   â”œâ”€ descriptive_numeric.csv
   â”œâ”€ churn_categorical_spread.csv
   â”œâ”€ churn_numeric_diff.csv
   â”œâ”€ correlation_matrix.csv (opcional)
   â”œâ”€ baseline_metrics.json (opcional â€“ modelo)
   â”œâ”€ model_prep_metadata.json (opcional â€“ metadata modelado)
   â””â”€ requisitos_checklist.csv
```

## ğŸ”„ Flujo MetodolÃ³gico
| Etapa | DescripciÃ³n | Resultado Clave |
|-------|-------------|-----------------|
| 1. ExtracciÃ³n | Carga desde JSON remoto (API Raw GitHub) | `TelecomX_Data_local.parquet` |
| 2. TransformaciÃ³n 2.1â€“2.5 | ExploraciÃ³n, diccionario, control de incoherencias, limpieza, derivaciones, estandarizaciÃ³n opcional | `TelecomX_transformado.parquet`, `TelecomX_limpio.parquet` |
| 3. AnÃ¡lisis (EDA) | Descriptivo, distribuciÃ³n de churn, categÃ³ricas, numÃ©ricas, correlaciones | CSVs de mÃ©tricas + grÃ¡ficos en notebook |
| 4. Modelado Baseline (Opcional) | RegresiÃ³n logÃ­stica sobre dataset preparado | `TelecomX_model_ready.parquet`, `baseline_metrics.json` |
| 5. Informe Final | SÃ­ntesis narrativa de pasos, hallazgos y recomendaciones | SecciÃ³n â€œInforme Finalâ€ en el notebook |
| 6. Checklist | VerificaciÃ³n automÃ¡tica de requisitos | `requisitos_checklist.csv` |

## ğŸ§ª Principales Transformaciones
- NormalizaciÃ³n de strings (espacios, casing, variantes Yes/No/SÃ­ â†’ 1/0).
- ConversiÃ³n de columnas *object* numÃ©ricas usando heurÃ­stica (>95% parseable).
- IdentificaciÃ³n y posible conversiÃ³n de fechas.
- DerivaciÃ³n de `Cuentas_Diarias` (MonthlyCharges / 30) si existe columna mensual.
- CreaciÃ³n de dataset listo para modelado (one-hot para baja cardinalidad + escalado numÃ©rico).

## ğŸ“Š AnÃ¡lisis Exploratorio Destacado
- Descriptivos para variables numÃ©ricas (`describe`).
- DistribuciÃ³n absoluta y porcentual de churn.
- Tasa de churn por categorÃ­a (spread para priorizar variables).
- Diferencias de medias y test t para numÃ©ricas clave.
- Heatmap de correlaciones (opcional, guardado como CSV).

## ğŸ¤– Modelo Baseline (Opcional)
- RegresiÃ³n LogÃ­stica con divisiÃ³n estratificada 75/25.
- MÃ©tricas guardadas: ROC-AUC, precision, recall, F1, soporte.
- Artefactos: `baseline_metrics.json`, matriz de confusiÃ³n, curva ROC (en notebook).

## âœ… Checklist de Requisitos
La Ãºltima celda del notebook genera un resumen y persiste `data/requisitos_checklist.csv` con el estado (True/False) de cada punto del flujo solicitado.

## ğŸš€ CÃ³mo Ejecutar (Local)
1. Crear entorno (opcional pero recomendado):
   ```bash
   python -m venv .venv
   # Windows PowerShell
   .venv\Scripts\Activate.ps1
   ```
2. Instalar dependencias mÃ­nimas:
   ```bash
   pip install pandas numpy pyarrow fastparquet seaborn matplotlib scikit-learn scipy
   ```
3. Abrir y ejecutar el notebook `TelecomX_LATAM.ipynb` en orden (o usar â€œRun Allâ€).
4. Revisar artefactos en `data/` y completar los placeholders del Informe Final con hallazgos concretos.

## ğŸ§· Reproducibilidad
- Se emplean formatos Parquet para eficiencia y consistencia de tipos.
- Limpieza y derivaciones idempotentes: al re-ejecutar, los archivos se sobre-escriben de forma controlada.
- Para congelar el entorno: `pip freeze > requirements-lock.txt`.

## ğŸ” Consideraciones de Calidad
- ConversiÃ³n robusta de tipos con manejo de errores.
- DetecciÃ³n de cardinalidad alta para evitar sobrecodificaciÃ³n.
- SeparaciÃ³n clara de dataset â€œlimpioâ€ vs â€œmodel readyâ€.

## ğŸ“ˆ Posibles Mejores Futuras
- Feature engineering temporal (cohortes, antigÃ¼edad segmentada).
- Modelos avanzados (Gradient Boosting, Random Forest, XGBoost, LightGBM).
- Interpretabilidad (SHAP, Permutation Importance).
- Ajuste de umbrales segÃºn costo de falsos negativos (churn real no detectado).
- Pipeline formal (scikit-learn `Pipeline` + validaciÃ³n cruzada estratificada).
- IntegraciÃ³n continua de mÃ©tricas (GitHub Actions).

## ğŸ—‚ï¸ Data Privacy
El dataset es pÃºblico (fuente del challenge). No se incluyen datos personales sensibles.

## ğŸ“œ Licencia
Agregar una licencia adecuada (ej.: MIT) en `LICENSE` si el repositorio se hace pÃºblico.

## ğŸ™Œ Agradecimientos
- Fuente del reto: Alura / Challenge Data Science LATAM.
- Comunidad open-source (pandas, scikit-learn, seaborn, etc.).

---
Si necesitas un `requirements.txt` generado o adaptaciÃ³n para despliegue (API / dashboard), abre un issue o aÃ±ade la solicitud.
